{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Human_activity_recognition.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm2FKSN9hMjQ"
      },
      "source": [
        "#Activity Recognition Using Smartphones Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktwNQFEVMc7T"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense \n",
        "from keras.layers import Flatten \n",
        "from keras.layers import Dropout \n",
        "from keras.layers import LSTM \n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBg8T9TPUCsM",
        "outputId": "46577f86-41af-4590-ed33-b307e6773fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7zAk9awMc7o"
      },
      "source": [
        "### loading data\n",
        "\n",
        "The movement data recorded was the x, y, and z accelerometer data (linear acceleration) and gyroscopic data (angular velocity) from the smart phone, specifically a Samsung Galaxy S II. Observations were recorded at 50 Hz (i.e. 50 data points per second). Each subject performed the sequence of activities twice; once with the device on their left-hand-side and once with the device on their right-hand side.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HMWczMAMc7p"
      },
      "source": [
        "def load_file(filepath):\n",
        "    df = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
        "    return df.values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7NImzxAMc77"
      },
      "source": [
        "#group for whether its test or train folder\n",
        "def load_group(filenames, prefix=''):\n",
        "    loaded = []\n",
        "    for filename in filenames:\n",
        "        data = load_file(prefix + filename)\n",
        "        loaded.append(data)\n",
        "    loaded = np.dstack(loaded)\n",
        "    return loaded"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdx2_9G4Mc8H"
      },
      "source": [
        "def load_dataset_group(group, prefix=''):\n",
        "    filepath = prefix + group + '/Inertial Signals/'\n",
        "    \n",
        "    filenames = []\n",
        "    #total acceleration\n",
        "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "    # body acceleration\n",
        "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "    # body gyroscope\n",
        "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "    \n",
        "    X = load_group(filenames, filepath)\n",
        "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02gBlpozMc8R"
      },
      "source": [
        "def load_dataset(prefix):\n",
        "  #load train data\n",
        "  train_X, train_y = load_dataset_group('train', prefix + 'UCI_HAR_Dataset/')\n",
        "  print(train_X.shape, train_y.shape)\n",
        "  #load test data\n",
        "  test_X, test_y = load_dataset_group('test', prefix+'UCI_HAR_Dataset/')\n",
        "  print(test_X.shape, test_y.shape)\n",
        "\n",
        "  train_y -= 1\n",
        "  test_y -= 1\n",
        "\n",
        "  # one hot encode label\n",
        "  train_y = to_categorical(train_y)\n",
        "  test_y = to_categorical(test_y)\n",
        "\n",
        "  print(train_y.shape, test_y.shape)\n",
        "  return train_X, train_y, test_X, test_y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y1uLld_QDr7"
      },
      "source": [
        "#lstm model with 2 lstm layers \n",
        "def evaluate_model(train_X, train_y, test_X, test_y):\n",
        "  verbose, epochs, bs = 0, 15, 64\n",
        "  n_timesteps, n_features, n_outputs = train_X.shape[1], train_X.shape[2], train_y.shape[1]\n",
        "\n",
        "  model = Sequential()\n",
        "  #return sequences to be able to add another lstm layer\n",
        "  model.add(LSTM(100, input_shape=(n_timesteps, n_features)))\n",
        "  #dropout to avoid overfitting\n",
        "  model.add(Dropout(0.5))\n",
        "  #a dense fully connected layer is used to interpret the features extracted by the LSTM \n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  # a dense layer to output class\n",
        "  model.add(Dense(n_outputs, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.fit(train_X, train_y, epochs=epochs, batch_size=bs, verbose=verbose)\n",
        "  _, accuracy = model.evaluate(test_X, test_y, batch_size=bs, verbose=0)\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eozzWLNhSeyq"
      },
      "source": [
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = np.mean(scores), np.std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boxOvNABSwK1"
      },
      "source": [
        "# run an experiment\n",
        "def run_experiment(repeats=10):\n",
        "\t# load data\n",
        "\ttrain_X, train_y, test_X, test_y = load_dataset('/content/drive/My Drive/Colab Notebooks/HAR/UCI HAR Dataset/')\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in range(repeats):\n",
        "\t\tscore = evaluate_model(train_X, train_y, test_X, test_y)\n",
        "\t\tscore = score * 100.0\n",
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O8ovj-CS3gS",
        "outputId": "daba01b3-ab64-48ba-dcbd-86db5065e743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "run_experiment(1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 6) (2947, 6)\n",
            ">#1: 91.686\n",
            "[91.68646335601807]\n",
            "Accuracy: 91.686% (+/-0.000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX7D0Q0PbpXD"
      },
      "source": [
        "### CNN-LSTM Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8v4LQygcwTI"
      },
      "source": [
        "def model_cnn_lstm(train_X, train_y, test_X, test_y):\n",
        "  verbose, epochs, bs = 0, 25, 64\n",
        "  n_timesteps, n_features, n_outputs = train_X.shape[1], train_X.shape[2], train_y.shape[1]\n",
        "\n",
        "  # reshape data into time steps of sub-sequences\n",
        "  n_steps, n_length = 4, 32\n",
        "  train_X = train_X.reshape((train_X.shape[0], n_steps, n_length, n_features))\n",
        "  test_X = test_X.reshape((test_X.shape[0], n_steps, n_length, n_features))\n",
        "  #model\n",
        "  model = Sequential()\n",
        "  model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
        "  model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
        "  model.add(TimeDistributed(Dropout(0.5)))\n",
        "  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "  model.add(TimeDistributed(Flatten()))\n",
        "  model.add(LSTM(100))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(n_outputs, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(train_X, train_y, epochs=epochs, batch_size=bs, verbose=verbose)\n",
        "  _, accuracy = model.evaluate(test_X, test_y, batch_size=bs, verbose=0)\n",
        "\n",
        "  return accuracy\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwCcDucbi9RV"
      },
      "source": [
        "# run an experiment\n",
        "def run_experiment_cnnlstm(repeats=10):\n",
        "\t# load data\n",
        "\ttrain_X, train_y, test_X, test_y = load_dataset('/content/drive/My Drive/Colab Notebooks/HAR/UCI HAR Dataset/')\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in range(repeats):\n",
        "\t\tscore = model_cnn_lstm(train_X, train_y, test_X, test_y)\n",
        "\t\tscore = score * 100.0\n",
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3Pa-0sEjAhg",
        "outputId": "e5e2d738-1a02-45dd-dade-27a233ea0408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "run_experiment_cnnlstm()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 6) (2947, 6)\n",
            ">#1: 90.940\n",
            ">#2: 91.585\n",
            ">#3: 91.076\n",
            ">#4: 90.838\n",
            ">#5: 91.110\n",
            ">#6: 91.890\n",
            ">#7: 88.836\n",
            ">#8: 90.635\n",
            ">#9: 90.499\n",
            ">#10: 92.060\n",
            "[90.93993902206421, 91.58466458320618, 91.07567071914673, 90.83814024925232, 91.10960364341736, 91.89005494117737, 88.83610367774963, 90.63454270362854, 90.49881100654602, 92.05971956253052]\n",
            "Accuracy: 90.947% (+/-0.857)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM09_-xPmgnp"
      },
      "source": [
        "### ConvLSTM Network Model\n",
        "\n",
        "The ConvLSTM2D class in keras expects data to have shape (samples, time, rows, cols, channels)\n",
        "\n",
        "\n",
        "*   Samples: n, for the number of windows in the dataset.\n",
        "* Time: 4, for the four subsequences that we split a window of 128 time steps into.\n",
        "* Rows: 1, for the one-dimensional shape of each subsequence.\n",
        "* Columns: 32, for the 32 time steps in an input subsequence.\n",
        "* Channels: 9, for the nine input variables.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AHs2yonjGZp"
      },
      "source": [
        "def model_convLSTM(train_X, train_y, test_X, test_y):\n",
        "  bs, epochs = 64, 25\n",
        "  n_timesteps, n_features, n_outputs = train_X.shape[1], train_X.shape[2], train_y.shape[1]\n",
        "\n",
        "  n_steps, n_length = 4, 32\n",
        "  train_X = train_X.reshape((train_X.shape[0], n_steps, 1, n_length, n_features))\n",
        "  test_X = test_X.reshape((test_X.shape[0], n_steps, 1, n_length, n_features))\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(n_outputs, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(train_X, train_y, batch_size=bs, epochs=epochs, verbose=0)\n",
        "  _ , accuracy = model.evaluate(test_X, test_y, batch_size=bs, verbose=0)\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgPPQy1Ort04"
      },
      "source": [
        "# run an experiment\n",
        "def run_experiment_convlstm(repeats=10):\n",
        "\t# load data\n",
        "\ttrain_X, train_y, test_X, test_y = load_dataset('/content/drive/My Drive/Colab Notebooks/HAR/UCI HAR Dataset/')\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in range(repeats):\n",
        "\t\tscore = model_convLSTM(train_X, train_y, test_X, test_y)\n",
        "\t\tscore = score * 100.0\n",
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RacrW_7TsJRW",
        "outputId": "c788619d-f4ca-4cc7-aed1-ba9201497530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "run_experiment_convlstm()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 6) (2947, 6)\n",
            ">#1: 90.024\n",
            ">#2: 91.076\n",
            ">#3: 91.008\n",
            ">#4: 90.397\n",
            ">#5: 90.193\n",
            ">#6: 90.668\n",
            ">#7: 89.447\n",
            ">#8: 89.141\n",
            ">#9: 90.906\n",
            ">#10: 91.042\n",
            "[90.0237500667572, 91.07567071914673, 91.00780487060547, 90.39701223373413, 90.19341468811035, 90.66847562789917, 89.44689631462097, 89.1414999961853, 90.90600609779358, 91.0417377948761]\n",
            "Accuracy: 90.390% (+/-0.651)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAYV87b0sLeX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}